merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30']
test_data <- sampled_ob['2014-07-01/2014-08-29']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print("N-network done")
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_ampds(data_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
i
file1
for (i in 12:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30']
test_data <- sampled_ob['2014-07-01/2014-08-29']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print("N-network done")
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_ampds(data_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
for (i in 12:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30 23:59:59']
test_data <- sampled_ob['2014-07-01/2014-08-29 23:59:59']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print("N-network done")
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_ampds(data_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
for (i in 13:length(fls)) {
}
for (i in 13:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30 23:59:59']
test_data <- sampled_ob['2014-07-01/2014-08-29 23:59:59']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print("N-network done")
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_ampds(data_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
i
for (i in 17:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30 23:59:59']
test_data <- sampled_ob['2014-07-01/2014-08-29 23:59:59']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print("N-network done")
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_ampds(data_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
i
for (i in 18:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30 23:59:59']
test_data <- sampled_ob['2014-07-01/2014-08-29 23:59:59']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print("N-network done")
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_ampds(data_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
agg_result <- do.call(rbind,day_pred_result)
write.csv(agg_result,file="prediction_result_REFIT_dataset.csv")
}
agg_result
i
file1
gt_data
head(sampled_ob)
compute_groundtruth_main_refit <- function(data_ob,past_days = 6,weekday_context = TRUE){
# main function used to establish ground truth, i.e., weather day is anomalous or not
# data_ob : basically read from file CCD_maincode2017.r
# past_days: no. of past days to establish ground truth
power_df <- data_ob$power
power_df$weekday <- ifelse(!weekdays(index(power_df)) %in% c("Saturday","Sunday"),1,0)
observe_data <- power_df['2014-06-01/2014-06-30 23:59:59']
label_data <-  power_df['2014-07-01/2014-08-29 23:59:59']
#past_days = 6
#weekday_context = TRUE # meaning weekday will use only weekdays for prediction
ob_days <- split.xts(observe_data,f="days",k=1)
lab_days <- split.xts(label_data,f="days",k=1)
annotated_days <- list()
for(i in 1:length(lab_days)){
if(!weekday_context){
# simple case : without weekday and weekend divison
op_days <- tail(ob_days,past_days)
annotated_days[[i]] <- establish_anomaly_groundtruth(op_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
# return(ob_days)
} else {
if(all(lab_days[[i]]$weekday==1)){ # is weekday
ind <- sapply(ob_days,function(x) unique(x$weekday))
ind_weekday <- which(ind == 1)
my_ob_days <- ob_days[tail(ind_weekday,past_days)]
annotated_days[[i]] <- establish_anomaly_groundtruth(my_ob_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
} else { # if weekend
week_days_no <- floor(past_days * 0.50) # 50% of weekdays and remaining weekend day
week_end_no <-  floor(past_days * 0.50)
ind <- sapply(ob_days,function(x) unique(x$weekday))
ind_weekday <- which(ind == 1)
ind_weekend <- which(ind == 0)
temp_ind <- sort(c(tail(ind_weekday,week_days_no),tail(ind_weekend,week_end_no)))
my_ob_days <- ob_days[temp_ind]
annotated_days[[i]] <- establish_anomaly_groundtruth(my_ob_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
}
gt_data <- do.call(rbind,annotated_days)
return(gt_data)
}
compute_groundtruth_main_refit <- function(data_ob,past_days = 6,weekday_context = TRUE){
# main function used to establish ground truth, i.e., weather day is anomalous or not
# data_ob : basically read from file CCD_maincode2017.r
# past_days: no. of past days to establish ground truth
power_df <- data_ob$power
power_df$weekday <- ifelse(!weekdays(index(power_df)) %in% c("Saturday","Sunday"),1,0)
observe_data <- power_df['2014-06-01/2014-06-30 23:59:59']
label_data <-  power_df['2014-07-01/2014-08-29 23:59:59']
#past_days = 6
#weekday_context = TRUE # meaning weekday will use only weekdays for prediction
ob_days <- split.xts(observe_data,f="days",k=1)
lab_days <- split.xts(label_data,f="days",k=1)
annotated_days <- list()
for(i in 1:length(lab_days)){
if(!weekday_context){
# simple case : without weekday and weekend divison
op_days <- tail(ob_days,past_days)
annotated_days[[i]] <- establish_anomaly_groundtruth(op_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
# return(ob_days)
} else {
if(all(lab_days[[i]]$weekday==1)){ # is weekday
ind <- sapply(ob_days,function(x) unique(x$weekday))
ind_weekday <- which(ind == 1)
my_ob_days <- ob_days[tail(ind_weekday,past_days)]
annotated_days[[i]] <- establish_anomaly_groundtruth(my_ob_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
} else { # if weekend
week_days_no <- floor(past_days * 0.50) # 50% of weekdays and remaining weekend day
week_end_no <-  floor(past_days * 0.50)
ind <- sapply(ob_days,function(x) unique(x$weekday))
ind_weekday <- which(ind == 1)
ind_weekend <- which(ind == 0)
temp_ind <- sort(c(tail(ind_weekday,week_days_no),tail(ind_weekend,week_end_no)))
my_ob_days <- ob_days[temp_ind]
annotated_days[[i]] <- establish_anomaly_groundtruth(my_ob_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
}
gt_data <- do.call(rbind,annotated_days)
return(gt_data)
}
fls
for (i in 1:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30 23:59:59']
test_data <- sampled_ob['2014-07-01/2014-08-29 23:59:59']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
#neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
#savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
#write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_refit(sampled_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
i
for (i in 12:length(fls)) {
# House 11 has data from 3 june
file1 <- fls[i]
data_ob <- create_weather_power_object_from_REFIT_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2014-06-01/2014-06-30 23:59:59']
test_data <- sampled_ob['2014-07-01/2014-08-29 23:59:59']
# regression_days <- sampled_ob['2014-07-10/2014-08-29']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#print("Regression done")
#neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
#savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
#write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
gt_data <- compute_groundtruth_main_refit(sampled_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
# l <- as.data.frame(plot_table(test_data,reg_result$fit,neural_result$fit,intent = "return"))
# l$home <- strsplit(file1,'[.]')[[1]][1]
# day_pred_result[[i]] <- l
}
read_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_neural_results/"
gt_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/refit_gt_results/"
fls <- list.files(read_dir,pattern="*.csv")
fls
for(i in 1:length(fls)){
file1 = fls[[i]]
neu_result <- fread(paste0(read_dir,file1))
neural_result <- xts(neu_result[,2:NCOL(neu_result)],fasttime::fastPOSIXct(neu_result$Index)-19800)
gt <- fread(paste0(gt_dir,file1))
gt_data <- xts(gt[,2:NCOL(gt)],fasttime::fastPOSIXct(gt$Index)-19800)
anomaly_window = 1
anomalythreshold_len <- 3
energy = compute_energy_savings(neural_result, gt_data, anomalythreshold_len=3,anomaly_window = 1)
print(energy)
}
rm(list=ls())
setwd("/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/")
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/ECO_dataset/"
fls <- list.files(path1,pattern = "*.csv")
fls
file2 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/ECO_dataset/ZurichWeather/weather_Zurich_complete.csv"
source("/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/CCD_supportcode2017.R")
day_pred_result <- list()
i
i=1
file1 <- fls[1]
file1
data_ob <- create_weather_power_object_from_ECO_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2012-08-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2012-10-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2012-08-01/2012-08-30 23:59:59']
test_data <- sampled_ob['2012-09-01/2012-10-30 23:59:59']
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
tail(test_data)
test_data <- sampled_ob['2012-09-01/2012-10-29 23:59:59']
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_gt_results/"
gt_data <- compute_groundtruth_main(sampled_ob,past_days = 6,weekday_context = TRUE)
head(sampled_ob)
compute_groundtruth_main_eco <- function(data_ob,past_days = 6,weekday_context = TRUE){
# main function used to establish ground truth, i.e., weather day is anomalous or not
# data_ob : basically read from file CCD_maincode2017.r
# past_days: no. of past days to establish ground truth
power_df <- data_ob$power
power_df$weekday <- ifelse(!weekdays(index(power_df)) %in% c("Saturday","Sunday"),1,0)
observe_data <- power_df['2012-08-01/2012-08-30 23:59:59']
label_data <-  power_df['2012-09-01/2012-10-29 23:59:59']
#past_days = 6
#weekday_context = TRUE # meaning weekday will use only weekdays for prediction
ob_days <- split.xts(observe_data,f="days",k=1)
lab_days <- split.xts(label_data,f="days",k=1)
annotated_days <- list()
for(i in 1:length(lab_days)){
if(!weekday_context){
# simple case : without weekday and weekend divison
op_days <- tail(ob_days,past_days)
annotated_days[[i]] <- establish_anomaly_groundtruth(op_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
# return(ob_days)
} else {
if(all(lab_days[[i]]$weekday==1)){ # is weekday
ind <- sapply(ob_days,function(x) unique(x$weekday))
ind_weekday <- which(ind == 1)
my_ob_days <- ob_days[tail(ind_weekday,past_days)]
annotated_days[[i]] <- establish_anomaly_groundtruth(my_ob_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
} else { # if weekend
week_days_no <- floor(past_days * 0.50) # 50% of weekdays and remaining weekend day
week_end_no <-  floor(past_days * 0.50)
ind <- sapply(ob_days,function(x) unique(x$weekday))
ind_weekday <- which(ind == 1)
ind_weekend <- which(ind == 0)
temp_ind <- sort(c(tail(ind_weekday,week_days_no),tail(ind_weekend,week_end_no)))
my_ob_days <- ob_days[temp_ind]
annotated_days[[i]] <- establish_anomaly_groundtruth(my_ob_days,lab_days[[i]])
ob_days[[length(ob_days)+1]] <- lab_days[[i]] #update observation_days
}
gt_data <- do.call(rbind,annotated_days)
return(gt_data)
}
gt_data <- compute_groundtruth_main_eco(sampled_ob,past_days = 6,weekday_context = TRUE)
gt_data
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
fls
i=3
fls[3]
file1 <- fls[3]
data_ob <- create_weather_power_object_from_ECO_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2012-08-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2012-10-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2012-08-01/2012-08-30 23:59:59']
test_data <- sampled_ob['2012-09-01/2012-10-29 23:59:59']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
# reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#  print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_gt_results/"
gt_data <- compute_groundtruth_main_eco(sampled_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
fls
fls[5]
file1 <- fls[5]
data_ob <- create_weather_power_object_from_ECO_dataset(path1,file1,file2)
#appliance_features <- get_appliance_features(path1, file1)
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
# USED DATA FROM 2012-08-01' to 2012-10-30
merge_start_date <- as.POSIXct(strptime('2012-08-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2012-10-30 23:59:59',format = "%Y-%m-%d"))
confirm_validity(data_ob, merge_start_date, merge_end_date)
my_range <- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather_ECOdata(data_ob,my_range)
train_data <- sampled_ob['2012-08-01/2012-08-30 23:59:59']
test_data <- sampled_ob['2012-09-01/2012-10-29 23:59:59']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
# reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
#  print("Regression done")
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
savedir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_neural_results/"
write.csv(fortify(neural_result),file=paste0(savedir,file1),row.names = FALSE)
#ESTABLISH GROUND TRUTH
savedir_gt <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_gt_results/"
gt_data <- compute_groundtruth_main_eco(sampled_ob,past_days = 6,weekday_context = TRUE)
write.csv(fortify(gt_data),file=paste0(savedir_gt,file1),row.names = FALSE)
read_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_neural_results/"
gt_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/results/eco_gt_results/"
fls <- list.files(read_dir,pattern="*.csv")
fls
for(i in 1:length(fls)){
file1 = fls[[i]]
neu_result <- fread(paste0(read_dir,file1))
neural_result <- xts(neu_result[,2:NCOL(neu_result)],fasttime::fastPOSIXct(neu_result$Index)-19800)
gt <- fread(paste0(gt_dir,file1))
gt_data <- xts(gt[,2:NCOL(gt)],fasttime::fastPOSIXct(gt$Index)-19800)
anomaly_window = 1
anomalythreshold_len <- 3
energy = compute_energy_savings(neural_result, gt_data, anomalythreshold_len=3,anomaly_window = 1)
print(energy)
}
