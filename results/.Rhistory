data_ob <- create_weather_power_object_fromAggDataport(path1,file1,file2)
#data_ob_eco <- create_weather_power_object_ECOdataset(eco_dataset_path,house_no)
# home_details <- get_appliance_features(path1, file1) # returns two things: appliance rating and dissagrigated energy
# replace above function with create_appliance_rating_file() function
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30',format = "%Y-%m-%d"))
confirm_validity(data_ob,merge_start_date,merge_end_date)
my_range<- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather(data_ob,my_range)
#sampled_ob <- combine_energy_weather(data_ob_eco,my_range) # FOR ECO DATASET
train_data <- sampled_ob['2014-06-01/2014-06-21']
test_data <- sampled_ob['2014-06-22/2014-07-30']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
# PREDICTION PART
#reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
# print_single_prediction_method_table(test_data, method_result = reg_result$fit)
#  plot_singlepredictor_graph(train_data,test_data,reg_result$fit)
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 15)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
plot_singlepredictor_graph(train_data,test_data,neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 4)
res_neu[res_neu==TRUE]
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 20)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
plot_singlepredictor_graph(train_data,test_data,neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 4)
res_neu[res_neu==TRUE]
hour <- 4
anomaly <-   rnorm(6*hour,1100,2) # 6 refers to the no. of observations per hour
anomaly_2 <- rnorm(6*hour,310,2) # for second appliance
start_time <- as.POSIXct("2014-07-05 07:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend1 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#2 AC took long cycles during day
hour2 <- 6
anomaly <- rep(c(rnorm(5,1100,1),rnorm(1,2,1)),hour2)
anomaly_2 <- rep(c(rnorm(5,310,1),rnorm(1,1,0.5)),hour2)
start_time <- as.POSIXct("2014-07-20 05:30:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend2 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend2
#3 AC works at unknown time
hour3 <- 5
anomaly <- rep(c(rnorm(4,1100,1),rnorm(2,2,1)),hour3)
anomaly_2 <- rep(c(rnorm(4,310,1),rnorm(2,1,0.5)),hour3)
start_time <- as.POSIXct("2014-07-28 12:40:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend3 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend3
#4 AC work for extra hours cycle
hour <- 6
anomaly <-   rnorm(6*hour,1100,2) # 6 refers to the no. of observations per hour
anomaly_2 <- rnorm(6*hour,310,2) # for second appliance
start_time <- as.POSIXct("2014-08-10 07:40:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend4 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#5 AC took long cycles during day
hour2 <- 6
anomaly <- rep(c(rnorm(5,1100,1),rnorm(1,2,1)),hour2)
anomaly_2 <- rep(c(rnorm(5,310,1),rnorm(1,1,0.5)),hour2)
start_time <- as.POSIXct("2014-08-18 07:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend5 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend5
#6 AC works at unknown time
hour3 <- 6
anomaly <- rep(c(rnorm(4,1100,1),rnorm(2,2,1)),hour3)
anomaly_2 <- rep(c(rnorm(4,310,1),rnorm(2,1,0.5)),hour3)
start_time <- as.POSIXct("2014-08-28 12:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend6 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend
insert_frame <- rbind(dframe_extend1,dframe_extend2,dframe_extend3,
dframe_extend4,dframe_extend5,dframe_extend6)
colnames(insert_frame) <- c("air1","furnace1")
head(insert_frame)
tail(insert_frame)
file1 <- "1037.csv"
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
df <- fread(paste0(path1,file1))
df_xts <- xts(df[,2:dim(df)[2]],fasttime::fastPOSIXct(df$localminute)-19800)
head(df,2)[,1]
head(df_xts,2)[,2]
df_orig <- df_xts["2014-06-1/2014-08-30"]
mutate_frame <- mutate_columns(df_orig,insert_frame)
save_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
mutate_csv <- data.frame(localminute=index(mutate_frame),coredata(mutate_frame))
write.csv(mutate_csv,file=paste0(save_dir,file1),row.names = FALSE)
file1 <- "1037.csv"
#house_no <- "house1_10min.csv"
#path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
print("reading mutated dataframe")
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
file2 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/weather/Austin2014/10minutely_Austinweather.csv"
#eco_dataset_path <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/ECO_dataset/"
source("/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/CCD_supportcode2017.R")
#data_ob <- create_weather_power_object(path1,file1,file2)
data_ob <- create_weather_power_object_fromAggDataport(path1,file1,file2)
#
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30',format = "%Y-%m-%d"))
confirm_validity(data_ob,merge_start_date,merge_end_date)
my_range<- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather(data_ob,my_range)
#sampled_ob <- combine_energy_weather(data_ob_eco,my_range) # FOR ECO DATASET
train_data <- sampled_ob['2014-06-01/2014-06-21']
test_data <- sampled_ob['2014-06-22/2014-07-30']
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 20)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
plot_singlepredictor_graph(train_data,test_data,neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 4)
res_neu[res_neu==TRUE]
dim(res_neu[res_neu==TRUE])
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 5)
res_neu[res_neu==TRUE]
dim(res_neu[res_neu==TRUE])
reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
print_single_prediction_method_table(test_data, method_result = reg_result$fit)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
train_data <- sampled_ob['2014-06-01/2014-06-30']
test_data <- sampled_ob['2014-07-01/2014-07-30']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
# PREDICTION PART
# reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
# print_single_prediction_method_table(test_data, method_result = reg_result$fit)
#  plot_singlepredictor_graph(train_data,test_data,reg_result$fit)
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 4)
res_neu[res_neu==TRUE]
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 5)
res_neu[res_neu==TRUE]
test_data <- sampled_ob['2014-07-01/2014-08-30']
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
plot_singlepredictor_graph(train_data,test_data,neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 5)
res_neu[res_neu==TRUE]
file1 <- "1086.csv"
#house_no <- "house1_10min.csv"
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
df <- fread(paste0(path1,file1))
df_xts <- xts(df[,2:dim(df)[2]],fasttime::fastPOSIXct(df$localminute)-19800)
head(df,2)[,1]
head(df_xts,2)[,2]
df_sub <- df_xts["2014-06-1/2014-08-30"]
head(df_sub)
dat = df_sub$air1
dat <-dat["2014-06-20/2014-06-21"]
dat2 <- fortify(dat)
colnames(dat2) <- c("Index","power")
g <- ggplot(dat2,aes(Index,power)) + geom_line()
ggplotly(g)
dat = df_sub$air1
dat <-dat["2014-06-01/2014-06-10"]
dat2 <- fortify(dat)
colnames(dat2) <- c("Index","power")
g <- ggplot(dat2,aes(Index,power)) + geom_line()
ggplotly(g)
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"use")
visualize_context_data_facet_form <- function(df,column_name){
month_data <- df
month_data <- month_data[,column_name]
colnames(month_data) <- "power"
#browser()
month_data$day <- lubridate::day(index(month_data))
month_data$time <- lubridate::hour(index(month_data)) * 60 + lubridate::minute(index(month_data))
# df_long <- reshape2::melt(coredata(month_data),id.vars=c("time","day"))
g <- ggplot(as.data.frame(coredata(month_data)),aes(time,power)) + geom_line() + facet_wrap(~day,ncol=7)
print(g)
}
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"use")
head(df_sub)
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"use")
dev.off()
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"use")
head(df_sub)
df_sub["2014-06-01/2014-06-30"]
visualize_context_data_facet_form <- function(df,column_name){
month_data <- df
month_data <- month_data[,column_name]
colnames(month_data) <- "power"
#browser()
month_data$day <- lubridate::day(index(month_data))
month_data$time <- lubridate::hour(index(month_data)) * 60 + lubridate::minute(index(month_data))
# df_long <- reshape2::melt(coredata(month_data),id.vars=c("time","day"))
g <- ggplot(as.data.frame(coredata(month_data)),aes(time,power)) + geom_line() + facet_wrap(~day,ncol=7)
print(g)
}
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"use")
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"air1")
visualize_context_data_facet_form(df_sub["2014-07-01/2014-07-30"],"air1")
visualize_context_data_facet_form(df_sub["2014-08-01/2014-08-30"],"air1")
visualize_context_data_facet_form(df_sub["2014-07-01/2014-07-30"],"air1")
visualize_context_data_facet_form(df_sub["2014-06-01/2014-06-30"],"use")
dataframe_visualize_all_columns(df_sub["2014-07-18"])
dataframe_visualize_all_columns <- function(dframe) {
library(RColorBrewer)# to increase no. of colors
library(plotly)
# VISUALIZE SPECiFIC PORTION OF DATA
#http://novyden.blogspot.in/2013/09/how-to-expand-color-palette-with-ggplot.html
#dframe <- data_10min["2014-08-9"]
dframe <- data.frame(timeindex=index(dframe),coredata(dframe))
# dframe$dataid <- NULL ; dframe$air1 <-NULL ; dframe$use<- NULL ; dframe$drye1 <- NULL
df_long <- reshape2::melt(dframe,id.vars = "timeindex")
colourCount = length(unique(df_long$variable))
getPalette = colorRampPalette(brewer.pal(8, "Dark2"))(colourCount) # brewer.pal(8, "Dark2") or brewer.pal(9, "Set1")
g <- ggplot(df_long,aes(timeindex,value,col=variable,group=variable))
g <- g + geom_line() + scale_colour_manual(values=getPalette)
ggplotly(g)
}
dataframe_visualize_all_columns(dat_new["2014-06-27/2014-06-30"])
dataframe_visualize_all_columns(df_sub["2014-07-18"])
dat = df_sub$air1
dat <-dat["2014-07-18"]
dat2 <- fortify(dat)
colnames(dat2) <- c("Index","power")
g <- ggplot(dat2,aes(Index,power)) + geom_line()
ggplotly(g)
visualize_context_data_facet_form(dat_new["2014-07-01/2014-07-30"],"use")
visualize_context_data_facet_form(df_sub["2014-07-01/2014-07-30"],"use")
file1 <- "1086.csv"
#house_no <- "house1_10min.csv"
#path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
print("reading mutated dataframe")
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
print("reading mutated dataframe")
#path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
file2 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/weather/Austin2014/10minutely_Austinweather.csv"
#eco_dataset_path <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/ECO_dataset/"
source("/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/CCD_supportcode2017.R")
#data_ob <- create_weather_power_object(path1,file1,file2)
data_ob <- create_weather_power_object_fromAggDataport(path1,file1,file2)
#data_ob_eco <- create_weather_power_object_ECOdataset(eco_dataset_path,house_no)
# home_details <- get_appliance_features(path1, file1) # returns two things: appliance rating and dissagrigated energy
# replace above function with create_appliance_rating_file() function
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30',format = "%Y-%m-%d"))
confirm_validity(data_ob,merge_start_date,merge_end_date)
my_range<- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather(data_ob,my_range)
#sampled_ob <- combine_energy_weather(data_ob_eco,my_range) # FOR ECO DATASET
train_data <- sampled_ob['2014-06-01/2014-06-30']
test_data <- sampled_ob['2014-07-01/2014-08-30']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
# PREDICTION PART
# reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
# print_single_prediction_method_table(test_data, method_result = reg_result$fit)
#  plot_singlepredictor_graph(train_data,test_data,reg_result$fit)
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 1,anomalythreshold_len = 5)
res_neu[res_neu==TRUE]
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 2,anomalythreshold_len = 8)
res_neu[res_neu==TRUE]
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 2,anomalythreshold_len = 10)
res_neu[res_neu==TRUE]
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 3,anomalythreshold_len = 16)
res_neu[res_neu==TRUE]
visualize_context_data_facet_form(df_sub["2014-07-01/2014-07-30"],"use")
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 3,anomalythreshold_len = 12)
res_neu[res_neu==TRUE]
dat = df_sub$air1
dat <-dat["2014-07-18"]
dat2 <- fortify(dat)
colnames(dat2) <- c("Index","power")
g <- ggplot(dat2,aes(Index,power)) + geom_line()
ggplotly(g)
dat = df_sub$air1
dat <-dat["2014-07-01/2014-07-10"]
dat2 <- fortify(dat)
colnames(dat2) <- c("Index","power")
g <- ggplot(dat2,aes(Index,power)) + geom_line()
ggplotly(g)
file1 <- "1086.csv"
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
df <- fread(paste0(path1,file1))
df_xts <- xts(df[,2:dim(df)[2]],fasttime::fastPOSIXct(df$localminute)-19800)
head(df,2)[,1]
head(df_xts,2)[,2]
df_orig <- df_xts["2014-06-1/2014-08-30"]
mutate_frame <- mutate_columns(df_orig,insert_frame)
save_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
mutate_csv <- data.frame(localminute=index(mutate_frame),coredata(mutate_frame))
file1
write.csv(mutate_csv,file=paste0(save_dir,file1),row.names = FALSE)
file1 <- "1086.csv"
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
file2 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/weather/Austin2014/10minutely_Austinweather.csv"
#eco_dataset_path <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/ECO_dataset/"
source("/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/CCD_supportcode2017.R")
#data_ob <- create_weather_power_object(path1,file1,file2)
data_ob <- create_weather_power_object_fromAggDataport(path1,file1,file2)
#data_ob_eco <- create_weather_power_object_ECOdataset(eco_dataset_path,house_no)
# home_details <- get_appliance_features(path1, file1) # returns two things: appliance rating and dissagrigated energy
# replace above function with create_appliance_rating_file() function
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30',format = "%Y-%m-%d"))
confirm_validity(data_ob,merge_start_date,merge_end_date)
my_range<- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather(data_ob,my_range)
#sampled_ob <- combine_energy_weather(data_ob_eco,my_range) # FOR ECO DATASET
train_data <- sampled_ob['2014-06-01/2014-06-30']
test_data <- sampled_ob['2014-07-01/2014-07-30']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
# PREDICTION PART
# reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
# print_single_prediction_method_table(test_data, method_result = reg_result$fit)
#  plot_singlepredictor_graph(train_data,test_data,reg_result$fit)
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 3,anomalythreshold_len = 12)
res_neu[res_neu==TRUE]
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 3,anomalythreshold_len = 12)
res_neu[res_neu==TRUE]
visualize_context_data_facet_form(mutate_frame["2014-07-01/2014-07-30"],"use")
dev.off()
visualize_context_data_facet_form(mutate_frame["2014-07-01/2014-07-30"],"use")
mutate_columns <- function(df_orig,insert_frame){
# function used to mutate columns of df_orig with synthetic data
cols <- colnames(insert_frame)
for(i in 1:length(cols)){
t_stamp <- index(insert_frame)
df_orig[t_stamp,'use'] <- df_orig[t_stamp,'use'] - df_orig[t_stamp,cols[i]]
df_orig[t_stamp,cols[i]] <- insert_frame[t_stamp,cols[i]]
df_orig[t_stamp,'use'] <- df_orig[t_stamp,'use'] + df_orig[t_stamp,cols[i]]
}
print ("mutation done")
return(df_orig)
}
head(insert_frame)
head(dframe_extend1)
hour <- 7
anomaly <-   rnorm(6*hour,1500,2) # 6 refers to the no. of observations per hour
anomaly_2 <- rnorm(6*hour,345,2) # for second appliance
start_time <- as.POSIXct("2014-07-04 01:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend1 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
head(dframe_extend1)
hour <- 7
anomaly <-   rnorm(6*hour,1500,2) # 6 refers to the no. of observations per hour
anomaly_2 <- rnorm(6*hour,345,2) # for second appliance
start_time <- as.POSIXct("2014-07-04 01:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend1 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#2 AC took long cycles during day
hour2 <- 8
anomaly <- rep(c(rnorm(6,1500,1),rnorm(1,2,1)),hour2)
anomaly_2 <- rep(c(rnorm(6,345,1),rnorm(1,1,0.5)),hour2)
start_time <- as.POSIXct("2014-07-12 11:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend2 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend2
#3 AC works at unknown time
hour3 <- 5
anomaly <-   rnorm(6*hour,1500,2) # 6 refers to the no. of observations per hour
anomaly_2 <- rnorm(6*hour,345,2) # for second appliance
start_time <- as.POSIXct("2014-07-18 13:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend3 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend3
hour <- 6
anomaly <-   rnorm(6*hour,1100,2) # 6 refers to the no. of observations per hour
anomaly_2 <- rnorm(6*hour,310,2) # for second appliance
start_time <- as.POSIXct("2014-08-10 07:40:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend4 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#5 AC took long cycles during day
hour2 <- 6
anomaly <- rep(c(rnorm(5,1100,1),rnorm(1,2,1)),hour2)
anomaly_2 <- rep(c(rnorm(5,310,1),rnorm(1,1,0.5)),hour2)
start_time <- as.POSIXct("2014-08-18 07:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend5 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend5
#6 AC works at unknown time
hour3 <- 6
anomaly <- rep(c(rnorm(4,1100,1),rnorm(2,2,1)),hour3)
anomaly_2 <- rep(c(rnorm(4,310,1),rnorm(2,1,0.5)),hour3)
start_time <- as.POSIXct("2014-08-28 12:00:00")
end_time <- start_time + (length(anomaly)-1)*10*60 # mins to seconds
time_sequence <- seq(start_time, end_time, by = "10 min")
dframe_extend6 <- xts(data.frame(anomaly,anomaly_2),time_sequence)
#dframe_extend
insert_frame <- rbind(dframe_extend1,dframe_extend2,dframe_extend3,
dframe_extend4,dframe_extend5,dframe_extend6)
colnames(insert_frame) <- c("air1","furnace1")
head(insert_frame)
file1 <- "1086.csv"
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/"
df <- fread(paste0(path1,file1))
df_xts <- xts(df[,2:dim(df)[2]],fasttime::fastPOSIXct(df$localminute)-19800)
head(df,2)[,1]
head(df_xts,2)[,2]
df_orig <- df_xts["2014-06-1/2014-08-30"]
mutate_frame <- mutate_columns(df_orig,insert_frame)
visualize_context_data_facet_form(mutate_frame["2014-07-01/2014-07-30"],"use")
save_dir <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
mutate_csv <- data.frame(localminute=index(mutate_frame),coredata(mutate_frame))
write.csv(mutate_csv,file=paste0(save_dir,file1),row.names = FALSE)
file1 <- "1086.csv"
#house_no <- "house1_10min.csv"
ath1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
path1 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/without_car/9appliances/mutated/"
path1
file2 <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/Dataport/weather/Austin2014/10minutely_Austinweather.csv"
#eco_dataset_path <- "/Volumes/MacintoshHD2/Users/haroonr/Detailed_datasets/ECO_dataset/"
source("/Volumes/MacintoshHD2/Users/haroonr/Dropbox/R_codesDirectory/R_Codes/KDD2017/CCD_supportcode2017.R")
#data_ob <- create_weather_power_object(path1,file1,file2)
data_ob <- create_weather_power_object_fromAggDataport(path1,file1,file2)
#data_ob_eco <- create_weather_power_object_ECOdataset(eco_dataset_path,house_no)
# home_details <- get_appliance_features(path1, file1) # returns two things: appliance rating and dissagrigated energy
# replace above function with create_appliance_rating_file() function
print("DATA RANGES ARE:")
print(paste0("Power data,","start: ",index(first(data_ob$power_data))," end: ",index(last(data_ob$power_data))))
print(paste0("Weather data,","start: ",index(first(data_ob$weather_data))," end: ",index(last(data_ob$weather_data))))
merge_start_date <- as.POSIXct(strptime('2014-06-01',format = "%Y-%m-%d"))
merge_end_date   <- as.POSIXct(strptime('2014-08-30',format = "%Y-%m-%d"))
confirm_validity(data_ob,merge_start_date,merge_end_date)
my_range<- paste0(merge_start_date,'/',merge_end_date)
sampled_ob <- combine_energy_weather(data_ob,my_range)
#sampled_ob <- combine_energy_weather(data_ob_eco,my_range) # FOR ECO DATASET
train_data <- sampled_ob['2014-06-01/2014-06-30']
test_data <- sampled_ob['2014-07-01/2014-07-30']
#regression_days <- sampled_ob['2014-06-26/2014-07-30']
#find_regrassivedays_with_BIC(regression_days) # USED TO FIND NO. OF BEST HISTORICAL DAYS FOR REGRESSION
# PREDICTION PART
# reg_result <- regression_procedure(train_data,test_data,hourwindow = 6)
# print_single_prediction_method_table(test_data, method_result = reg_result$fit)
#  plot_singlepredictor_graph(train_data,test_data,reg_result$fit)
neural_result <- neuralnetwork_procedure(train_data,test_data,hourwindow = 6, daywindow = 30)
print_single_prediction_method_table(test_data, method_result = neural_result$fit)
res_neu <- find_anomalous_status(test_data,result=neural_result,anomaly_window = 3,anomalythreshold_len = 12)
res_neu[res_neu==TRUE]
str(neural_result)
head(neural_result)
neural_result["2014-07-01"]
neural_result["2014-07-04"]
neural_result["2014-07-12"]
head(test_data)
result=neural_result
suppressWarnings(rm("status"))
df_comp  <- cbind(result,test_data)
df_comp
head(df_comp)
df_days <- split.xts(df_comp,f="days",k=1) # daywise dataframe
pastanomaly_vec <- as.vector("numeric") # keeps track of possible anomalies in last window
length(df_days)
anomaly_window=3
i=1
day_hour <- split_hourwise(df_days[[i]],windowsize = anomaly_window)
length(day_hour)
day_hour
j=1
decision_vector <- as.vector(ifelse(day_hour[[j]]$power > day_hour[[j]]$upr,1,0))
decision_vector <- c(pastanomaly_vec,decision_vector)
decision_vector
length(decision_vector)
length_list <- rle(decision_vector) # run length encoding
length_list
is_anom <- any(length_list$lengths >= anomalythreshold_len & length_list$values == 1) #http://stackover
anomalythreshold_len=4
is_anom <- any(length_list$lengths >= anomalythreshold_len & length_list$values == 1) #http://stackover
is_anom
cnt <- 0; lcs <- 0 #last common sequence with status as 1
length(decision_vector)
decision_vector[length(decision_vector) - cnt]
rle(c(0,0,0,1,1,1))
rle(c(0,0,0,1,1,0,0,1))
table(c(0,0,0,1,1,0,0,1))
p <- table(c(0,0,0,1,1,0,0,1))
p
str(p)
p$1
p[1]
p==1
names(p)
p['1']
p['0']
p["0"]
p["0"][1]
print(p["0"])
print(as.numeric(p["0"]))
is_anom
